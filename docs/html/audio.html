<!-- HTML header for doxygen 1.8.3.1-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.3.1"/>
<title>Smart Remote 3 nRF52 v1.2 : Audio subsystem</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="extra_stylesheet_offline.css" rel="stylesheet" type="text/css"/>
<link href="nordic.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0" width="100%" class="blank">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Nordic Semiconductor" src="nordic_small.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">Smart Remote 3 nRF52 v1.2
   </div>
  </td>
 </tr>
 </tbody>
</table>
<script>
var url=window.location.href.split("/").reverse()[1];
var validLinks= ["nrf5","s130","s132","s212","s332"];
var index;
for (index = 0; index < validLinks.length; ++index) {
   if ( url.indexOf(validLinks[index]) !== -1 ) {
      document.getElementById(validLinks[index]).setAttribute('class', 'doclinks docselected');
   };
};
</script>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.3.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Introduction</span></a></li>
      <li><a href="usergroup0.html"><span>API&#160;Reference</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('audio.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Data Structures</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Groups</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Audio subsystem </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Smart Remote features a comprehensive audio subsystem that lets you customize your remote to different use cases involving audio input.</p>
<h1><a class="anchor" id="audio_functionality"></a>
Audio functionality</h1>
<p>Smart Remote provides the capability to perform a variety of audio processing operations on audio data.</p>
<ul>
<li>Capturing<ul>
<li>PDM: 16-bit at 8/16/24/32 kHz</li>
</ul>
</li>
<li>Processing<ul>
<li>Gain</li>
<li>Equalizer</li>
<li>Active Noise Reduction (ANR)</li>
</ul>
</li>
<li>Compressing<ul>
<li>Four codecs are available: ADPCM, BroadVoice32 (BV32FP), Opus (SILK and CELT), SBC (including mSBC)</li>
</ul>
</li>
<li>Transmitting<ul>
<li>Voice over HID over GATT (VoHoG)</li>
<li>Android TV Voice Service (ATVV)</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="audio_architecture"></a>
Audio architecture</h1>
<p>Two different memory pools play a crucial role in the audio architecture - the audio buffer pool and the audio frame pool. Both of them involve data circulation and function on a loop basis - buffers and frames are allocated, processed, and then returned to the pool to be reused.</p>
<p>Audio buffer characteristics:</p>
<ul>
<li>Holds uncompressed audio data.</li>
<li>Size in samples defines time span.</li>
<li>Size in bytes equals to<div class="fragment"><div class="line"><span class="keyword">sizeof</span>(int16_t) * &lt;number of samples&gt; </div>
</div><!-- fragment --></li>
</ul>
<p>Audio frame characteristics:</p>
<ul>
<li>Holds compressed audio data.</li>
<li>Size in samples equals to the size of the audio buffer.</li>
<li>Size in bytes depends on codec bit rate (might be variable).</li>
</ul>
<div class="image">
<img src="audio_buffers_frames.svg" alt="audio_buffers_frames.svg"/>
<div class="caption">
Audio buffer and audio frame pools</div></div>
<ol type="1">
<li>The microphone (or microphones) that collects audio input is connected to the pulse density modulation (PDM) interface of the nRF52 SoC.</li>
<li>When audio input appears, the PDM interface starts to fill audio buffers. These buffers are allocated from a memory pool called the audio buffer pool.</li>
<li>When a buffer has been filled with audio data, an event is scheduled to the background scheduler. The background scheduler holds a pointer to the buffer as an argument to the event handler.</li>
<li>Background scheduler runs the <code>m_audio_process()</code> function, which gets the audio buffer as an argument.</li>
<li>The function converts the buffer into an audio frame according to the configured audio specification. The frame is allocated from a memory pool called the audio frame pool. The processed audio buffer is returned to the buffer pool.</li>
<li>The frame transmission is then scheduled to the foreground scheduler.</li>
<li>After data is sent, the frame returns to the audio frame pool and can be reused.</li>
</ol>
<p>This kind of frame and buffer management mechanism allows for compensating the jitter of calling the <code>m_audio_process()</code> function (related to greater CPU usage), as well as the jitter of data transmission.</p>
<p>There are certain situations in which the audio system might lose data. Each of these situations is clearly signaled as a warning on the console and included in audio statistics.</p>
<ul>
<li>The PDM interface cannot allocate a buffer on time, for example, because the buffer pool is empty. <div class="fragment"><div class="line">&lt;warning&gt; drv_audio_pdm: drv_audio_pdm_event_handler(): WARNING: Cannot allocate audio buffer! </div>
</div><!-- fragment --></li>
<li>The <code>m_audio_process</code> function cannot allocate a frame and process the buffer as a consequence. In such case, the buffer is freed without processing and its data is lost. <div class="fragment"><div class="line">&lt;warning&gt; m_audio: m_audio_process(): WARNING: Cannot allocate audio frame! </div>
</div><!-- fragment --></li>
<li>A frame is created but it cannot be sent. The frame is freed to the frame pool and data is lost. <div class="fragment"><div class="line">&lt;warning&gt; m_audio: m_audio_process(): WARNING: Cannot schedule audio frame transmission! </div>
</div><!-- fragment --></li>
</ul>
<p>The audio module gathers information about lost frames and buffers. These statistics can be viewed using <a class="el" href="audio.html#audio_gauges">Audio gauges</a> of <a class="el" href="audio.html#audio_cli">Audio CLI commands</a>.</p>
<h1><a class="anchor" id="audio_sizes"></a>
Buffer and frame sizes</h1>
<p>One execution of the <code>m_audio_process()</code> function corresponds to one buffer being converted into a frame.</p>
<p>Buffers hold data in PCM format which means that each of them takes considerable amounts of memory. However, the scheduling applied in the audio subsystem is optimized in such a way to have fewer buffers, which is possible because of relatively small jitter during audio processing.</p>
<p>Frames require less memory because they hold compressed data. However, more of them are required because jitter and latency are higher during the transmission. Even though buffers and corresponding frames differ in terms of used memory, they carry the same number of samples.</p>
<p>The frame size fully depends on the used codec and its configuration. When you choose and configure a particular codec, the following defines are set automatically:</p>
<ul>
<li><code>CONFIG_FRAME_SIZE_SAMPLES</code> - Determines the number of audio samples a frame can hold.</li>
<li><code>CONFIG_FRAME_SIZE_MS</code> - Determines the duration of audio samples a frame can hold.</li>
<li><code>CONFIG_FRAME_SIZE_BYTES</code> - Determines the maximum size of a frame, in bytes.</li>
</ul>
<p>The frame size in bytes and its duration in ms determines its maximum bit rate. A frame can be smaller (containing fewer bytes) and thus bit rate might be reduced.</p>
<h1><a class="anchor" id="audio_sampling"></a>
Configured sampling and actual sampling</h1>
<p>The configured frame size in ms does not precisely reflect its actual value. The audio codecs available for Smart Remote support the standard sampling frequencies: 8 kHz, 16 kHz, 24 kHz, or 32 kHz. However, because of its characteristics, the nRF52 SoC cannot achieve exactly such sampling frequencies, which results in a discrepancy. For example, with 16000 Hz configured as the sampling frequency, the actual frequency is 16125 Hz, which means that 125 more samples are produced per second. The bit rate is also affected by this mechanism.</p>
<p>The used codec still treats the configured sampling value as the actual one. That is why, when configuring the codec, you must use the idealized sampling values. On the other hand, when analyzing audio using command-line tools, the audio subsystem shows the actual sampling and bit rate values.</p>
<h1><a class="anchor" id="audio_codecs_configs"></a>
Audio codecs configuration</h1>
<p>The audio subsystem features four codecs that can be used for compressing audio data: ADPCM, BV32FP, Opus CELT/SILK, and SBC/mSBC. The following table presents their available configurations in terms of bit rate and sampling rate :</p>
<table class="doxtable">
<tr style="height: 20px;">
<th style="height: 20px; text-align: center;">Codec </th><th style="height: 20px; text-align: center;">Sampling Frequency </th><th style="height: 20px; text-align: center;">Bit rate  </th></tr>
<tr style="height: 20px;">
<td style="height: 80px; text-align: center;" rowspan="4">ADPCM </td><td style="height: 20px; text-align: center;">8 kHz </td><td style="height: 20px; text-align: center;">32 kbit/s  </td></tr>
<tr style="height: 20px;">
<td style="height: 20px; text-align: center;">16 kHz </td><td style="height: 20px; text-align: center;">64 kbit/s  </td></tr>
<tr style="height: 20px;">
<td style="height: 20px; text-align: center;">24 kHz </td><td style="height: 20px; text-align: center;">96 kbit/s  </td></tr>
<tr style="height: 20px;">
<td style="height: 20px; text-align: center;">32 kHz </td><td style="height: 20px; text-align: center;">128 kbit/s  </td></tr>
<tr style="height: 20px;">
<td style="height: 20px; text-align: center;">BV32FP </td><td style="height: 20px; text-align: center;">16 kHz </td><td style="height: 20px; text-align: center;">32 kbit/s  </td></tr>
<tr style="height: 20px;">
<td style="height: 60px; text-align: center;" rowspan="3">Opus CELT </td><td style="height: 20px; text-align: center;">8 kHz </td><td style="height: 20px; text-align: center;">Configurable: VBR or CVBR/CBR 16-128 kbit/s  </td></tr>
<tr style="height: 20px;">
<td style="height: 20px; text-align: center;">16 kHz </td><td style="height: 20px; text-align: center;">Configurable: VBR or CVBR/CBR 16-128 kbit/s  </td></tr>
<tr style="height: 20px;">
<td style="height: 20px; text-align: center;">24 kHz </td><td style="height: 20px; text-align: center;">Configurable: VBR or CVBR/CBR 16-128 kbit/s  </td></tr>
<tr style="height: 20px;">
<td style="height: 40px; text-align: center;" rowspan="2">Opus SILK </td><td style="height: 20px; text-align: center;">8 kHz </td><td style="height: 20px; text-align: center;">Configurable: VBR or CVBR/CBR 16-128 kbit/s  </td></tr>
<tr style="height: 20px;">
<td style="height: 20px; text-align: center;">16 kHz </td><td style="height: 20px; text-align: center;">Configurable: VBR or CVBR/CBR 16-128 kbit/s  </td></tr>
<tr style="height: 20px;">
<td style="height: 40px; text-align: center;" rowspan="2">SBC </td><td style="height: 20px; text-align: center;">16 kHz </td><td style="height: 20px; text-align: center;">Depends on codec configuration  </td></tr>
<tr style="height: 20px;">
<td style="height: 20px; text-align: center;">32 kHz </td><td style="height: 20px; text-align: center;">Depends on codec configuration  </td></tr>
<tr style="height: 20px;">
<td style="height: 40px; text-align: center;" rowspan="2">mSBC </td><td style="height: 20px; text-align: center;">16 kHz </td><td style="text-align: center; height: 20px;">62.5 kbit/s  </td></tr>
<tr style="height: 20px;">
<td style="height: 20px; text-align: center;">32 kHz </td><td style="text-align: center; height: 20px;">125 kbit/s  </td></tr>
</table>
<h1><a class="anchor" id="audio_transports"></a>
Audio transports</h1>
<p>Two different BLE Services can be used for transmission of the compressed audio frames: Voice over HID over GATT (VoHoG) and Voice over BLE for Android TV (ATVV). At least one or both of these must be enabled in order to use the audio feature (see <a class="el" href="ble_services.html">BLE services</a> for details).</p>
<p>The <a class="el" href="packet_scheduling.html">Packet scheduling</a> mechanism applies to both services.</p>
<h2><a class="anchor" id="audio_transports_vohog"></a>
Voice over HID over GATT</h2>
<p>Voice over HID over GATT (VoHoG) uses the standard HID over GATT (HoG) service to transmit compressed audio frames as HID Vendor Reports. Frames are fragmented into one or more chunks which are transmitted one at a time as HID reports. The host receives the chunk(s) and decompresses the audio frame for playback using the chosen codec (see <a class="el" href="nvs.html">Nordic Voice System</a> for host-side details).</p>
<p>See <a class="el" href="hid_subsystem.html">HID state subsystem</a> for details regarding the HID subsystem, and <a class="el" href="_h_i_d.html">HID report descriptor</a> for HID descriptor and packet format details.</p>
<h2><a class="anchor" id="audio_transports_atvv"></a>
Android TV Voice Service</h2>
<p>Android TV Voice (ATVV) Service can be used for audio transmission to the Android TV host.</p>
<p>See <a class="el" href="group___m_o_d___c_o_m_s___b_l_e___a_t_v_v.html">Voice over BLE for Android implementation</a> for implementation details. If further information is required, please contact Google.</p>
<dl class="section note"><dt>Note</dt><dd>ATVV Service has restrictions regarding audio codec choice and microphone sampling rate. These restrictions also apply to VoHoG when both Services are enabled.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Consider this transport as an experimental feature, which can change at any time. Currently, v0.4 is supported.</dd></dl>
<h1><a class="anchor" id="audio_gauges"></a>
Audio gauges</h1>
<p>A highly configurable audio subsystem offers great flexibility. In order to ease its tuning and monitoring, a special infrastructure, called Audio Gauges, was created. When Audio Gauges are enabled (<a class="el" href="group__sr3__config__nrf52832__pca63519.html#gae01c38fd42c36818d094f3202b329577">CONFIG_AUDIO_GAUGES_ENABLED</a> is set to 1), detailed statistics are collected during audio transmission. After stopping an audio transfer, they are logged and can be observed on the console: </p>
<div class="fragment"><div class="line">&lt;info&gt; m_audio: Enabled</div>
<div class="line">&lt;info&gt; drv_audio_codec: OPUS/CELT Codec initialized (mode: VBR, complexity: 0, frame: 20 ms).</div>
<div class="line">&lt;info&gt; m_audio: Disabled</div>
<div class="line">&lt;info&gt; m_audio_gauges: Buffers processed: 222, lost: 0, discarded: 0 (loss ratio: 0%, discard ratio: 0%)</div>
<div class="line">&lt;info&gt; m_audio_gauges: Frames processed: 219, lost: 0, discarded: 1 (loss ratio: 0%, discard ratio: 0%)</div>
<div class="line">&lt;info&gt; m_audio_gauges:  Bitrate (min/avg/max): 14/16/21 kbit/s</div>
<div class="line">&lt;info&gt; m_audio_gauges:  CPU usage (min/avg/max): 54%/57%/64%</div>
<div class="line">&lt;info&gt; m_audio_gauges:       - ANR CPU usage (min/avg/max): 23%/26%/31%</div>
<div class="line">&lt;info&gt; m_audio_gauges:       - Codec CPU usage (min/avg/max): 26%/29%/32%</div>
</div><!-- fragment --><p>Audio gauges show audio frame and buffer statistics, bit rate information, and audio subsystem load (also referred to as "CPU usage" or "CPU load") of each audio processing stage, as well as of the audio subsystem as a whole. The CPU usage is calculated as a relation of an audio frame's duration to the time that the CPU needs to process this frame. For example, if a frame holds 20 ms of audio data but processing of it takes 30 ms, the CPU load will be indicated as 150%. If CPU load over 100% persists for a longer period of time, the buffer pool will be depleted and it will no longer be possible to compensate latency using them. Audio data is lost in such case. Short periods of CPU load over 100% are tolerated and can be compensated, as long as there are buffers in the buffer pool.</p>
<h1><a class="anchor" id="audio_cli"></a>
Audio CLI commands</h1>
<p>Statistics gathered by Audio Gauges, in greater detail and augmented by memory usage information, can be also viewed in real time using dedicated inspection commands through the command line interface: </p>
<div class="fragment"><div class="line">SR3-RTT&gt; audio info</div>
<div class="line">Configuration:</div>
<div class="line">        Sampling Frequency:     16125 Hz</div>
<div class="line">        Frame Length:           19.84 ms (320 samples, up to 102 bytes/frame = 41 kbit/s)</div>
<div class="line"></div>
<div class="line">Status: Enabled</div>
<div class="line">        Capture time:           3:07</div>
<div class="line">        Frame loss ratio:       0% (0 out of 9452 frames)</div>
<div class="line">        Bit rate:               18 kbit/s (min/avg/max: 15/18/26 kbit/s)</div>
<div class="line"></div>
<div class="line">        CPU Usage:              58% (min/avg/max: 52%/58%/66%)</div>
<div class="line">            - ANR:              27% (min/avg/max: 23%/27%/33%)</div>
<div class="line">            - Codec:            29% (min/avg/max: 26%/29%/39%)</div>
<div class="line"></div>
<div class="line">        Buffer Pool Usage:      50% (2 out of 4 buffers)</div>
<div class="line">            - Maximum:          75% (3 out of 4 buffers)</div>
<div class="line"></div>
<div class="line">        Frame Pool Usage:       0% (0 out of 6 frames)</div>
<div class="line">            - Maximum:          16% (1 out of 6 frames)</div>
</div><!-- fragment --><p>The commands might be also used to dynamically alter the configuration of the audio subsystem. The following commands are supported:</p>
<ul>
<li><code>audio driver info</code><br/>
 Prints information about the configuration and state of the audio capture driver.</li>
</ul>
<ul>
<li><code>audio driver set gain &lt;gain&gt;</code><br/>
 <code>audio driver set gain &lt;L-gain&gt; &lt;R-gain&gt;</code><br/>
 Allows to set decimator gain. Gain is specified in dB and ranges from -20 dB to +20 dB.</li>
</ul>
<ul>
<li><code>audio info</code><br/>
 Prints information about the configuration and state of the audio processing module.</li>
</ul>
<ul>
<li><code>audio codec info</code><br/>
 Prints information about codec configuration.</li>
</ul>
<ul>
<li><code>audio codec set complexity &lt;0-10&gt;</code><br/>
 Allows to set Opus codec complexity level. This command is available only when Opus codec is used.</li>
</ul>
<ul>
<li><code>audio codec set bitrate auto</code><br/>
 <code>audio codec set bitrate &lt;bitrate&gt; [vbr|cbr]</code><br/>
 Allows to set bit rate (specified in kbit/s), as well as bit rate control scheme. Note that actual bit rate never exceeds the limit set by the <a class="el" href="group__sr3__config__nrf52832__pca63519.html#gaa940976f23e9aff88240911bb24c236b">CONFIG_OPUS_BITRATE_LIMIT</a> option. This command is available only when Opus codec is used. </li>
</ul>
</div></div><!-- contents -->
</div><!-- doc-content -->
<div id="nav-path" class="topicfooter">
<a href="mailto:docfeedback@nordicsemi.no?subject=Documentation%20feedback" id="maillink">Documentation feedback</a> | <a href="https://devzone.nordicsemi.com/questions/" target="_blank">Developer Zone</a> | <a href="http://response.nordicsemi.com/subscribe-to-our-newsletters" target="_blank">Subscribe</a> | Updated <span id="date"/>
<script>
var date = new Date("Thu Jun 7 2018" + " UTC");
document.getElementById("date").innerHTML = date.toJSON().slice(0, 10);
var url=window.location.href.split("?")[0];
var filename=url.substring(url.lastIndexOf('/')+1);
document.getElementById("maillink").href = "mailto:docfeedback@nordicsemi.no?subject=Documentation%20feedback"+decodeURIComponent("%26")+"body=File%20name%3A%20"+encodeURIComponent(filename);
</script>
</div>
</body>
</html>
